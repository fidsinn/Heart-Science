---
title: "Heart Disease Science (extended version)"
author: "Finn B."
date: "2/9/2021"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
    number_sections: yes
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
  pdf_document: default
urlcolor: purple
linkcolor: purple
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
if(!require(psych)) install.packages("psych", repos = "http://cran.us.r-project.org")
if(!require(plyr)) install.packages("plyr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(ggthemes)) install.packages("ggthemes", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(rafalib)) install.packages("rafalib", repos = "http://cran.us.r-project.org")
if(!require(kernlab)) install.packages("kernlab", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rattle)) install.packages("rattle", repos = "http://cran.us.r-project.org")
if(!require(pROC)) install.packages("pROC", repos = "http://cran.us.r-project.org")

library(psych)
library(plyr)
library(tidyverse)
library(ggthemes)
library(kableExtra)
library(rafalib)
library(kernlab)
library(caret)
library(rpart)
library(rattle)
library(pROC)
```

```{r digits, include=FALSE}
options(digits = 3)
```

```{r readData, include=FALSE}
HeartData <- read_csv("data/heartdata.csv")
```

![](./resources/title.png)

# Introduction  

**To make sure the links work properly, please download the document from Github.**  

The purpose of this report is the analysis and methodology of several health data of patients from 1988. The data shows if a patient has [heart disease](https://www.mayoclinic.org/diseases-conditions/heart-disease/symptoms-causes/syc-20353118). It describes a range of conditions that are in connection with the heart. The data set used is a data set provided by **Donald Bren School of Information and Computer Sciences** from the **University of California, Irvine** originally. This project will concentrate on a database from the **V.A. Medical Center, Long Beach and Cleveland Clinic Foundation** created by **Robert Detrano, M.D., Ph.D.**. The data was sourced from [Kaggle](https://www.kaggle.com/ronitf/heart-disease-uci), where the data was initially processed.  
Origin of this database: [Archive.ics.uci](https://archive.ics.uci.edu/ml/datasets/heart+disease)  
First step is exploration and cleaning of the dataset. After that, each attribute is examined for its relation to the target variable. In the section of modeling, several classification methods are run through to predict whether a patient has heart disease or not. The methods used are **logistic regression**, **decision tree**, **random forest**, **support vector machine** and **k-nearest neighbors**. In results the methods will be compared by **confusion matrix derivations** and **area under the roc-curve**.

# Data exploration and cleaning  
## Data exploration

This report excludes 62 attributes from the original database to work only with a subset of 14 attributes, containing **13 features** and **one outcome variable** to consider if a patient has heart disease. The database contains health data of **303 patients**.  
On a first view you can see what features will accompany the final outcome variable in this project. Before heading into the analysis we need to understand what the different attributes tell us:
```{r headHeartData, echo=FALSE}
head(HeartData) %>% 
  knitr::kable() %>%
  kableExtra::kable_styling(latex_options="scale_down")
```

## Data cleaning
For data cleaning, some data from the original data base was changed. The levels of 'sex' were changed to 'female' and 'male'. The levels of 'target' were changed to 'disease' and 'no disease' to have a quiet better overview. Furthermore some of the attributes were encoded as factors to enable a better work: **sex, cp, fbs, restecg, exang, slope, ca, thal, disease(target)**.  

```{r clean_sex, echo=TRUE, results="hidden"}
HeartData$sex <- factor(HeartData$sex)
levels(HeartData$sex) <- c("female", "male")
```

```{r clean_cp, echo=TRUE, results="hidden"}
HeartData$cp <- factor(HeartData$cp)
levels(HeartData$cp) <- c("asymptomatic", 
                          "atypical angina", 
                          "non anginal pain", 
                          "typical angina")
```

```{r clean_fbs, echo=TRUE, results="hidden"}
HeartData$fbs <- factor(HeartData$fbs)
levels(HeartData$fbs) <- c("<=120", 
                           ">120")
```

```{r clean_restecg, echo=TRUE, results="hidden"}
HeartData$restecg <- factor(HeartData$restecg)
levels(HeartData$restecg) <- c("left vetricular hypertrophy", 
                               "normal",
                               "st-t abnormality")
```

```{r clean_exang, echo=TRUE, results="hidden"}
HeartData$exang <- factor(HeartData$exang)
levels(HeartData$exang) <- c("no", 
                               "yes")
```

```{r clean_slope, echo=TRUE, results="hidden"}
HeartData$slope <- factor(HeartData$slope)
levels(HeartData$slope) <- c("downsloping", 
                             "flat",
                             "upsloping")
```

```{r clean_ca, echo=TRUE, results="hidden"}
HeartData$ca <- factor(HeartData$ca)
levels(HeartData$ca) <- c(0, 1, 2, 3, NA)
```

```{r clean_thal, echo=TRUE, results="hidden"}
HeartData$thal <- factor(HeartData$thal)
levels(HeartData$thal) <- c(NA, 
                            "fixed defect", 
                            "normal", 
                            "reversible defect")
```

```{r clean_disease, echo=TRUE, results="hidden"}
HeartData$disease <- HeartData$target
HeartData$target <- NULL
HeartData$disease <- factor(HeartData$disease)
levels(HeartData$disease) <- c("disease", "no disease")
attr(HeartData, 'spec') <- NULL
```

Attribute   | Meaning
----------- | --------
age | Patients age (29-77 years)
sex | Female (0) and Male (1)
cp - **chest pain type** | asymptomatic (0); atypical angina (1); non-anginal pain (2); typical angina (3)
trestbps - **resting blood pressure** | in mm/Hg on admission to the hospital^1^
chol - **serum cholesterol** | in mg/dl
fbs - **fasting blood sugar** | > 120 mg/dl; no(0) yes(1)
restecg - **resting electrocardiographic results**| probable or definite left ventricular hypertrophy by Estes' criteria(0); normal(1); having ST-T wave abnormality(2)
thalach | maximum heart rate achieved
exang - **exercise induced angina** | no(0); yes(1)
oldpeak | ST depression induced by exercise relative to rest
slope - **slope of peak exercise ST segment** | downsloping(0); flat(1); upsloping(2)
ca - **number of major vessels colored by flouroscopy** | vessels(0-3); NA(4)
thal - **Thalium Stress Test Result** | NA(0); fixed defect(1); normal(2); reversible defect(3)
disease - **angiographic disease status** | > 50% diameter narrowing (0); < 50% diameter narrowing (1)

***

^1^ Judging from the values, the [systolic pressure](https://www.nhs.uk/common-health-questions/lifestyle/what-is-blood-pressure/) (the pressure when the heart pushes blood out) is given here.

```{r headHeartData2, echo=FALSE}
head(HeartData) %>% 
  knitr::kable() %>%
  kableExtra::kable_styling(latex_options="scale_down")
```

# Data analysis  
In this part of the project we will dig deeper into the attributes and potential effects on the disease. But first we will have a look on the categorization of disease and on the most obvious and superficial indicators: Age and Sex.  

## Disease

To determine the diagnosis of heart disease status the [angiographic disease](https://www.mayoclinic.org/tests-procedures/coronary-angiogram/about/pac-20384904) status was used. This was differentiated into two conditions that differ in the percentage diameter narrowing of <50% and >50% of coronary arteries.
```{r disease_summary, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(disease) %>%
  summarize("cases"=n()) %>%
  knitr::kable() %>% 
  kable_styling(full_width = FALSE)
```

As we can see the proportion of patients with disease also called prevalence was at 45.5% in the database.  

\newpage

## Age  

```{r age_summary, echo=FALSE, message=FALSE, comment=NA}
summary(HeartData$age)
```

```{r age_dist, echo=FALSE, message=FALSE}
HeartData %>%
  mutate(age_rnd=round(age, digits=-1)) %>%
  group_by(age_rnd) %>%
  summarize(count=n()) %>%
  ggplot(aes(age_rnd, count, fill="darkred")) +
  geom_bar(stat="identity") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  xlab("age")
```

\  

The age range goes from 29 years to 77 year. The median age is at 55 years, while we can see that the most patients are between 55 and 65 years.

This distribution can also be determined by the distribution of patients divided into disease and no disease where most patients with disease are in this range of age.  
```{r disease_age, echo=FALSE}
HeartData %>%
  group_by(disease, age) %>%
  ggplot(aes(disease, age, col=disease)) +
  geom_violin(alpha=0.3) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())
```

\newpage

## Sex  

```{r sex_count, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(sex) %>%
  summarize('count'=n(), disease=mean(disease=="disease")) %>%
  knitr::kable() %>% 
  kable_styling(full_width = FALSE)
```

\  

The distribution by sex is dominated by male patients, around 68% of the patients are male.  
The mean age of female patients is quite lower than the mean age of male patients.  

This can be seen in the mean of patients **with** heart diseases as well.  
**female:**  
```{r summary_female_age, echo=FALSE, comment=NA}
hd_female <- HeartData %>%
  filter(sex=="female" & disease=="disease")

hd_female$age %>%  
  summary()
```

**male:**  
```{r summary_male_age, echo=FALSE, comment=NA}
hd_male <- HeartData %>%
  filter(sex=="male" & disease=="disease")

hd_male$age %>%  
  summary()
```

```{r sex_age_count, echo=FALSE, message=FALSE}
HeartData %>%
  mutate(age_rnd=round(age, digits=-1)) %>%
  group_by(age_rnd, sex) %>%
  summarize(count=n()) %>%
  ggplot(aes(x=age_rnd, y=count, fill=sex)) +
  geom_bar(stat="identity", position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("age")
```

\  

As we can see in the following plot there are much more female patients without heart disease than with heart disease. Furthermore the number of male patients with and without diseases seem to be similar while there are more male patients around 60 with heart disease.  
```{r sex_age_disease, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(sex, age) %>%
  ggplot(aes(x=sex, y=age, fill=disease)) +
  geom_dotplot(binaxis = "y", 
               stackdir = "center", 
               alpha=0.7, 
               binwidth = 1.5) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())
```

\newpage

## Chest pain type {#cp}  

As previously researched, there are four types of chest pain. **Asymptomatic** pain means that a patient has no symptoms/pain. [Angina](https://www.mayoclinic.org/diseases-conditions/angina/symptoms-causes/syc-20369373) is a pain that the patient has near the heart, often described as chest tightness. Angina pain is categorized into **atypical** angina and **typical** angina.  
Most patients data shows asymptomatic and non anginal pain. Only a small amount of patients had typical angina:  
```{r cp_dist, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(cp) %>%
  summarize(count=n()) %>%
  ggplot(aes(cp, count/sum(count), fill=count)) +
  geom_bar(stat="identity") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  xlab("chest pain type") +
  ylab("proportion") +
  scale_fill_gradient(low="purple", high="red")
```

\  

Something that may not have been expected by many is the following result. Except of asymptomatic pain the proportion of patients with disease is far below 50% for each category of pain.  
```{r cp_disease_calc, echo=FALSE, message=FALSE}
HeartData %>%
  group_by('chest pain'=cp) %>%
  summarize('disease (prop)'=mean(disease=="disease")) %>%
  knitr::kable() %>% 
  kable_styling(full_width = FALSE)
```

```{r cp_disease_dist, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(cp, disease) %>%
  summarize(count=n()) %>%
  ggplot(aes(cp, count/sum(count), fill=disease)) +
  geom_bar(stat="identity", position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("chest pain type") +
  ylab("proportion")
```

\newpage

## Resting blood pressure {#trestbps}  
For most patients (68%) the blood pressure is higher than the [ideal systolic blood pressure](https://www.nhs.uk/common-health-questions/lifestyle/what-is-blood-pressure/#:~:text=For%20example%2C%20if%20your%20blood,be%20140%2F90mmHg%20or%20higher) of between 90 and 120mm/Hg. In the second plot we can observe a slightly increasing proportion of disease with a higher systolic resting blood pressure.
```{r ideal_trestbps_prop, echo=FALSE}
HeartData %>%
  summarize("trestbps <= 120mm/Hg"=mean(trestbps<=120), "trestbps > 120mm/Hg"=mean(trestbps>120)) %>%
knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

```{r trestbps_disease_dist, echo=FALSE, message=FALSE}
HeartData %>%
  mutate(trestbps_rnd=round(trestbps, digits=-1)) %>%
  group_by(trestbps_rnd, disease) %>%
  summarize(count=n()) %>%
  ggplot(aes(trestbps_rnd, count/sum(count), fill=disease)) +
  geom_bar(stat="identity", position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("resting blood pressure") +
  ylab("proportion")
```

```{r trestbps_disease_age, echo=FALSE, message=FALSE}
HeartData %>%
  mutate(trestbps_rnd=round(trestbps, digits=-1)) %>%
  group_by(trestbps_rnd) %>%
  summarize(prop_disease=mean(disease=="disease"), 
            prop_age=round(mean(age), digits = 0), 
            count=n()) %>%
  filter(count>=5) %>%
  ggplot(aes(trestbps_rnd, prop_disease, fill="")) +
  geom_bar(stat="identity") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("resting blood pressure") +
  ylab("proportion (disease)") +
  theme(legend.position = "none")
```

\newpage

## Serum cholesterol {#chol}  
Since there is too little information about what type of cholesterol level is given we assume total cholesterol. [Healthy cholesterol level](https://medlineplus.gov/cholesterollevelswhatyouneedtoknow.html) for adults is between 125mg/dL and 200mg/dL.

Most patients serum cholesterol is higher than the healthy range:  
```{r chol_count, echo=FALSE, message=FALSE}
HeartData %>%
  mutate(chol_rnd=round(chol, digits=-1)) %>%
  group_by(chol_rnd) %>%
  ggplot(aes(x=chol_rnd, y = ..prop.., fill=ifelse(chol<=200, "Normal","Highlighted"))) +
  geom_bar() +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  xlab("serum cholesterol") +
  ylab("percentage") +
  geom_vline(xintercept = 125) +
  geom_vline(xintercept = 200)
```

This can also be seen in comparison between diseased and healthy patients. The median (seen in the plot) of cholesterol of both groups is higher than 200 while cholesterol in the group of diseased patients is slightly higher.
```{r disease.chol.med, echo=TRUE, message=FALSE}
HD.chol.median.mean <- HeartData %>%
  group_by(disease) %>%
  summarize(me=mean(chol), med=median(chol))

HD.chol <- HeartData %>%
  group_by(disease) %>%
  select(disease, chol)
  
  ggplot(data=HD.chol, aes(disease, chol, color=disease)) +
  geom_jitter(width = 0.4, alpha = 0.3, size=4) +
  stat_smooth(method="lm", formula=disease~1, se=FALSE) +
  geom_hline(data=HD.chol.median.mean, aes(yintercept = med, color=disease)) +
  geom_hline(yintercept=200, linetype = "dashed") +
  xlab("Disease") +
  ylab("Cholesterol") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none")
```

\newpage

## Fasting blood sugar {#fbs}  
Normal [blood sugar levels](https://www.diabetes.co.uk/diabetes_care/blood-sugar-level-ranges.html) of **non-diabetic** people are between **72mg/dL** and **99mg/dL** when fasting. Fasting blood sugar levels of **100mg/dL** up to **125mg/dL** are already described as **prediabetic**, while **fbs > 125mg/dL** are diagnosed as **diabetic**.  
The study shows two possible outcomes of **fbs**: **<= 120mg/dL** and **>120mg/dL**.It must be considered, that people with a **fbs >120mg/dL** are at greater risk of developing heart disease or [cardiovascular disease](https://www.nhs.uk/conditions/cardiovascular-disease/), however the symptoms of the patient may be caused by diabetes and secondary diseases.  

Only a few patients have blood sugar levels in the range where diabetes would be diagnosed. The number of patients with and without disease are similar. The most patients have fasting blood sugar levels of 120 and lower.  
```{r fbs_disease, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(fbs, disease) %>%
  summarize(count=n()) %>%
  ggplot(aes(fbs, count, fill=disease)) +
  geom_bar(stat="identity", position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("fasting blood sugar (mg/dL)")
```

```{r fbs_prev, include=FALSE}
HeartData %>%
  summarize(mean(fbs==">120"))
```

There were 14.90% of patients with a critical value of fasting blood sugar level in the database, while the prevalence of diabetes in the US was 4.90%^2^ in the year 1990. So we can observe a much higher prevalence of patients with diabetes in the study from 1988 than in the total population.  

^2^[Diabetes trends in the U.S.: 1990-1998](https://care.diabetesjournals.org/content/23/9/1278#:~:text=RESULTS%3A%20The%20prevalence%20of%20diabetes,levels%2C%20and%20nearly%20all%20states.)  

\newpage

## Resting electrocardiographic results {#restecg}  
As results of the [restecg](https://www.mayoclinic.org/tests-procedures/ekg/about/pac-20384983) there are three potential outcomes:  

* **left ventricular hypertrophy:**  
[Left ventricular hypertrophy](https://www.mayoclinic.org/diseases-conditions/left-ventricular-hypertrophy/symptoms-causes/syc-20374314) is enlargement and thickening (hypertrophy) of the walls of the heart's main pumping chamber.
* **Normal:**  
No abnormalities or hypertrophies.
* **Having ST-T wave abnormality:**  
Abnormalities of **ST-** and/or **T wave** in the imaging procedures of the electrocardiogram.

```{r restecg_disease, echo=FALSE}
HeartData %>%
  group_by(restecg, disease) %>%
  ggplot(aes(x=restecg, 
             y=..count../sum(..count..), 
             fill=disease)) +
  geom_bar(position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  ylab("proportion")
```

\newpage

## THALACH {#thalach}  
THALACH is the **maximum heart rate** that has been achieved of each patient.  
We observe a lower maximum heart rate for patients with disease than without disease:  
```{r disease_thalach, echo=FALSE, message=FALSE}
HeartData %>%
  ggplot(aes(x=disease, y=thalach, color=disease)) +
  geom_jitter(width = 0.3, alpha = 0.3, size=4) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  ylab("thalach")
```

```{r thalach_mean_median, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(disease) %>%
  summarize(mean=mean(thalach), median=median(thalach)) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

As you can see in the next chart the average maximum heart rate decreases with age. An interesting abnormality is that patients with heart disease show a lower maximum heart rate at almost any age.  
```{r age_mean_thalach_disease, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(age, disease) %>%
  summarize(count=n(), mean_thalach=mean(thalach)) %>%
  filter(count>1) %>%
  ggplot(aes(x=age, y=mean_thalach, color=disease)) +
  geom_point() +
  geom_smooth(span = 0.5) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  ylab("thalach (mean)")
```

\newpage

## Exercise induced angina {#exang}  
We can assume that angina indicates heart disease at exercise more often than without. We can tell by the fact that most patients with exercise induced angina had heart disease but only a minority of patients with heart disease had angina outside the exercises (most were asymptomatic^3^ ).
```{r exang_disease, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(exang, disease) %>%
  ggplot(aes(exang, ..count../sum(..count..), fill=disease)) +
  geom_bar(position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("exercise induced angina") +
  ylab("proportion")
```

^3^ chest pain type and disease

\newpage

## ST depression induced by exercise relative to rest {#oldpeak}  
We can see that a greater [ST depression](https://litfl.com/st-segment-ecg-library/) is a sign of an increased probability of heart disease. The following findings from the database show, that the ST depression increase at exercise for patients with heart disease is greather than for patients without heart disease:  
```{r disease_oldpeak, echo=FALSE, message=FALSE}
HD.oldpeak.median.mean <- HeartData %>%
  group_by(disease) %>%
  summarize(me=mean(oldpeak), med=median(oldpeak))

HeartData %>%
  ggplot(aes(disease, oldpeak, color=disease)) +
  geom_jitter(width = 0.4, alpha = 0.3, size=4) +
  geom_hline(data=HD.oldpeak.median.mean, aes(yintercept = med, color=disease)) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  ylab("ST depression (relative)")
```

```{r oldpeak_mean_median, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(disease) %>%
  summarize(mean=mean(oldpeak), median=median(oldpeak)) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```
Median (seen in the plot) and mean show higher values of ST depression relation in people with heart disease than in people without heart disease.  

\newpage

## Slope of peak exercise ST segment {#slope}  
By the slope of [ST segment](https://litfl.com/st-segment-ecg-library/) we can see a higher proportion of patients in categories **flat slope** and **downsloping depression** that have disease than of patients without disease.  
```{r slope_disease, echo=FALSE, message=FALSE}
HeartData %>%
  group_by(slope, disease) %>%
  ggplot(aes(slope, ..count../sum(..count..), fill=disease)) +
  geom_bar(position="dodge") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  xlab("slope of ST segment") +
  ylab("proportion")
```

\newpage

## Major vessels colored by flouroscopy {#ca}  

[Flouroscopy](https://www.hopkinsmedicine.org/health/treatment-tests-and-therapies/fluoroscopy-procedure) is an imaging tool which is made for looking on several body systems. In this case the flouroscopy was used to observe the flow of blood through three major vessels in order to evaluate the presence of arterial blockages.  

```{r ca_disease, echo=FALSE, message=FALSE}
HeartData %>%
  filter(!is.na(ca)) %>%
    group_by(ca) %>%
    ggplot(aes(ca, ..count../sum(..count..), fill=disease)) +
    geom_bar(position="dodge") +
    theme_fivethirtyeight() +
    theme(axis.title = element_text()) +
    xlab("colored vessels") +
    ylab("proportion")
```

The next plot shows that the more vessels are colored by flouroscopy the higher the proportion of patients with disease.  
```{r ca_disease_mean, echo=FALSE, message=FALSE}
HeartData %>%
  filter(!is.na(ca)) %>%
  group_by(ca) %>%
  summarize(ca_mean=mean(disease=="disease")) %>%
  ggplot(aes(ca, ca_mean, fill=ca_mean)) +
  geom_bar(stat="identity") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  xlab("colored vessels") +
  ylab("proportion of disease") +
  scale_fill_gradient(low="lightblue", high="red")
```

\newpage

## Thalium Stress Test Result {#thal}  

[Thalium Stress Test](https://www.healthline.com/health/thallium-stress-test) is a test used to measure how the blood flow works while exercising or resting.  
The result was divided into normal result, fixed defect and reversible defect.  
```{r thal_disease, echo=FALSE, message=FALSE}
HeartData %>%
  filter(!is.na(thal)) %>%
    group_by(thal) %>%
    ggplot(aes(thal, ..count../sum(..count..), fill=disease)) +
    geom_bar(position="dodge") +
    theme_fivethirtyeight() +
    theme(axis.title = element_text()) +
    xlab("thalium stress test result") +
    ylab("proportion")
```

In the next plot we can see that the proportion of diseased patients at normal thalium stress test results is near 20%. While for any type of defect it is higher than 60%.  
```{r thal_disease_mean, echo=FALSE, message=FALSE}
HeartData %>%
  filter(!is.na(thal)) %>%
  group_by(thal) %>%
  summarize(thal_mean=mean(disease=="disease")) %>%
  ggplot(aes(thal, thal_mean, fill=thal_mean)) +
  geom_bar(stat="identity") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text(), legend.position = "none") +
  xlab("thalium stress test result") +
  ylab("proportion of disease") +
  scale_fill_gradient(low="lightblue", high="red")
```

\newpage

# Methods  
## Training and testing set  
In order to run different machine learning methods on the data we will first check the dataset on NA values. And exclude these entries from the upcoming modelings  
```{r sumNA, echo=TRUE, comment=NA}
sum(is.na(HeartData))
#HeartData %>% filter_all(any_vars(is.na(.)))
HeartData <- HeartData[complete.cases(HeartData), ]
```

To get reproducible results a seed has been set with as.integer(Sys.time()) using the last five characters.  
```{r set.seed, echo=TRUE, warning=FALSE}
set.seed(50866)
```

The data will be partitioned into two sets of 70% of the data for training and 30% of the data for testing.  
```{r dataPartition, echo=TRUE, warning=FALSE}
test_index <- createDataPartition(y = HeartData$disease,
                                  p = 0.7,
                                  list = FALSE)
training <- HeartData[test_index,]
testing <- HeartData[-test_index,]

levels(training$disease) <- c("disease", "no disease")
training$disease <- factor(training$disease, 
                           levels = levels(training$disease), 
                           labels = make.names(levels(training$disease)))

levels(testing$disease) <- c("disease", "no disease")
testing$disease <- factor(testing$disease, 
                          levels = levels(testing$disease), 
                          labels = make.names(levels(testing$disease)))
```

Running functions of the caret package for the next model prediction attempts already brings cross validation as default but we will use repeated cross validation with 3 repeats.  
```{r control.repeat, echo=TRUE, warning=FALSE}
control.repeat <- trainControl(method = "repeatedcv", 
                               number = 10,
                               repeats = 3,
                               classProbs=T,
                               savePredictions = T)
```

To run the k-nearest neighbors algorithm later, the categorical data of the training and testing data will be encoded by the onehot encoding method using dummy variables. We will set this data to binary variables and get a data frames of 29 columns each. This data will be used for the kNN-Algorithm exclusively.  
```{r onehot.encoding}
#one hot encoding (Training data)
Training.dummy <- dummyVars(" ~.", data=training)
training.onehot <- data.frame(predict(Training.dummy, newdata = training))
training.onehot$disease.no.disease <- factor(training.onehot$disease.no.disease)
levels(training.onehot$disease.no.disease) <- c("disease", "no disease")
training.onehot$disease.no.disease <- factor(training.onehot$disease.no.disease, 
                                             levels = levels(training.onehot$disease.no.disease), 
                                             labels = make.names(levels(training.onehot$disease.no.disease)))
training.onehot$disease.disease <- NULL
#one hot encoding (Testing data)
Testing.dummy <- dummyVars(" ~.", data=testing)
testing.onehot <- data.frame(predict(Testing.dummy, newdata = testing))
testing.onehot$disease.no.disease <- factor(testing.onehot$disease.no.disease)
levels(testing.onehot$disease.no.disease) <- c("disease", "no disease")
testing.onehot$disease.no.disease <- factor(testing.onehot$disease.no.disease, 
                                             levels = levels(testing.onehot$disease.no.disease), 
                                             labels = make.names(levels(testing.onehot$disease.no.disease)))
testing.onehot$disease.disease <- NULL
```

\newpage

## Logistic regression  
Because the heart disease dataset is a categorical problem we choose the logistic regression as the first modeling approach. **Binomial** as the **'family'**-parameter indicates that the generalized linear model method is logistic regression.  
```{r Train.glm, echo=TRUE}
#train logistic regression (generalized linear model)
Train.glm <- caret::train(disease ~ ., data=training,
                   method="glm",
                   trControl=control.repeat,
                   family="binomial",
                   na.action=na.exclude)
#apply model on testing
Model.glm.roc <- predict(Train.glm, testing, type="prob")
Model.glm <- predict(Train.glm, testing, type="raw")
#confMatrix
Conf.glm <- confusionMatrix(Model.glm, testing$disease)
```

```{r print_Conf.glm, echo=FALSE}
Conf.glm$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.glm <- Conf.glm$byClass[c("Sensitivity")]
Spec.glm <- Conf.glm$byClass[c("Specificity")]
Acc.glm <- Conf.glm$overall[["Accuracy"]]
F1.glm <- F_meas(Model.glm, testing$disease)
Prec.glm <- Conf.glm$byClass[c("Precision")]
Prev.glm <- Conf.glm$byClass[c("Prevalence")]
tibble(
  Method=c("Logistic regression"), 
  Sensitivity=c(Sens.glm),
  Specificity=c(Spec.glm),
  Accuracy=c(Acc.glm)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

\newpage

## Decision Tree  
Decision trees are pretty suitable for the purpose of identifying if several indicators implicate diseases or not.  
We have used the train function from the caret package and set the rpart method. TuneLength is set to 10, which means that the function uses ten different hyperparameters and chooses the best fitting for the training data. The hyperparameter of rpart is the **complexity parameter**.  
```{r Train.dec.tree, echo=TRUE}
#train decision tree
Train.dec.tree <- caret::train(disease ~ ., data=training,
                        method="rpart",
                        trControl=control.repeat,
                        tuneGrid=expand.grid(cp=0.001),
                        # tuneLength=10,
                        na.action=na.exclude)
#apply model on testing
Model.dec.tree.roc <- predict(Train.dec.tree, testing, type="prob")
Model.dec.tree <- predict(Train.dec.tree, testing, type="raw")
#confMatrix
Conf.dec.tree <- confusionMatrix(table(Model.dec.tree, testing$disease))
```

* 74.10% of patients would have been diagnosed correctly to have heart disease (sensitivity)
* 81.20% of patients would have been diagnosed correctly to have no heart disease (specificity)
* The overall accuracy of the decision tree is 78.00%.  

```{r print_Conf.dec.tree, echo=FALSE}
Conf.dec.tree$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.dec.tree <- confusionMatrix(Model.dec.tree, testing$disease)$byClass[c("Sensitivity")]
Spec.dec.tree <- confusionMatrix(Model.dec.tree, testing$disease)$byClass[c("Specificity")]
Acc.dec.tree <- confusionMatrix(Model.dec.tree, testing$disease)$overall[["Accuracy"]]
F1.dec.tree <- F_meas(Model.dec.tree, testing$disease)
Prec.dec.tree <- Conf.dec.tree$byClass[c("Precision")]
Prev.dec.tree <- Conf.dec.tree$byClass[c("Prevalence")]
tibble(
  Method=c("Decision tree"), 
  Sensitivity=c(Sens.dec.tree),
  Specificity=c(Spec.dec.tree),
  Accuracy=c(Acc.dec.tree)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

The following classification tree shows that the data was first split at the result of [thal](#thal). Furthermore split at [oldpeak](#oldpeak), [chol](#chol), [age](#age), [slope](#slope) and [sex](#sex).  

* 27% of all patients were predicted to have an abnormal thal and an oldpeak of $\geq$ 0.9
    + 88% of these patients were predicted to have **heart disease** 
* 9% of patients were predicted to have an abnormal thal, an oldpeak of < 0.9 and chol < 241
    + 68% of these patients were predicted to have **no heart disease** 
* 7% of all patients were predicted to have a normal thal, age $\geq$ 56, flat or downsloping slope and age < 66 
    + 86% of these patients were predicted to have **heart disease** 
* 32% of the patients were predicted to have a normal thal and age <56
    + 91% of these patients were predicted to have **no heart disease** 

```{r plot_Train.dec.tree, echo=FALSE}
fancyRpartPlot(Train.dec.tree$finalModel, sub="")
```

*Split of categorical data is between 1 (true) and 0 (false) - e.g. thalnormal < 0.5 means all abnormal thal results.  

\newpage

## Random forest  
With the random forest as an extension of the decision tree there is a high potential in outperforming a single tree by using several hundred trees. The number of trees is set to default (n=500).  
```{r Train.random.forest, echo=TRUE, warning=FALSE}
#train random forest
Train.random.forest <- caret::train(disease ~ ., data=training,
                             method="rf",
                             preProcess=c("center","scale"),
                             tuneLength=10,
                             trControl=control.repeat,
                             na.action=na.exclude)
#apply model on testing
Model.random.forest <- predict(Train.random.forest, testing, type="raw")
Model.random.forest.roc <- predict(Train.random.forest, testing, type="prob")
#confMatrix
Conf.random.forest <- confusionMatrix(Model.random.forest, testing$disease)
```

```{r print_Conf.random.forest, echo=FALSE}
Conf.random.forest$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$byClass[c("Sensitivity")]
Spec.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$byClass[c("Specificity")]
Acc.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$overall[["Accuracy"]]
F1.random.forest <- F_meas(Model.random.forest, testing$disease)
Prec.random.forest <- Conf.random.forest$byClass[c("Precision")]
Prev.random.forest <- Conf.random.forest$byClass[c("Prevalence")]
tibble(
  Method=c("Random forest"), 
  Sensitivity=c(Sens.random.forest),
  Specificity=c(Spec.random.forest),
  Accuracy=c(Acc.random.forest)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

As we can see the random forest outperformes the decision tree. Now we run this function with different amounts of ntree:  
```{r best_ntree, results="hide", warning=FALSE}
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
  fit <- train(disease~., data=training, 
               method="rf", 
               metric="Accuracy",
               preProcess=c("center","scale"),
               tuneGrid=expand.grid(.mtry=c(sqrt(ncol(training)))),
               trControl=control.repeat,
               ntree=ntree)
  key <- toString(ntree)
  modellist[[key]] <- fit
}
results <- resamples(modellist)
```

In the next plot we can see that the highest accuracy of the random forest is located at an amount of 2500 trees.  
```{r rf.accuracy_dotplot, echo=FALSE}
dotplot(results, ylab="nTree")
```

So we correct the amount of trees upwards.
```{r Train.random.forest.NEW, echo=TRUE}
Train.random.forest <- caret::train(disease ~ ., data=training,
                             method="rf",
                             trControl=control.repeat,
                             ntree=2000,
                             tuneLength=10,
                             # tuneGrid = data.frame(mtry = sqrt(ncol(training))),
                             na.action=na.exclude
)
Model.random.forest <- predict(Train.random.forest, testing, type="raw")
Model.random.forest.roc <- predict(Train.random.forest, testing, type="prob")
Conf.random.forest <- confusionMatrix(Model.random.forest, testing$disease)
```

```{r print_Conf.random.forest2, echo=FALSE}
Conf.random.forest$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$byClass[c("Sensitivity")]
Spec.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$byClass[c("Specificity")]
Acc.random.forest <- confusionMatrix(Model.random.forest, testing$disease)$overall[["Accuracy"]]
F1.random.forest <- F_meas(Model.random.forest, testing$disease)
Prec.random.forest <- Conf.random.forest$byClass[c("Precision")]
Prev.random.forest <- Conf.random.forest$byClass[c("Prevalence")]
tibble(
  Method=c("Random forest"), 
  Sensitivity=c(Sens.random.forest),
  Specificity=c(Spec.random.forest),
  Accuracy=c(Acc.random.forest)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Finally for random forest we have a look on the importance score of each variable in the dataset. We have already seen the attributes with the highest importance in the decision tree as decision at quite high nodes.  
```{r varImp_Train.random.forest, echo=FALSE, comment=NA}
varImp(Train.random.forest)
```

\newpage

## Support vector machine  
With the support vector machine we choose a linear method. Using a tuneLength of 5 the train function searches for the optimal tuning parameter of cost.  
```{r train.svmLinear, echo=TRUE, warning=FALSE}
#train svmLinear
Train.svmLinear <- caret::train(disease ~ ., data=training,
                         method = "svmLinear",
                         trControl= control.repeat,
                         preProcess=c("center",
                                      "scale"),
                         # tuneGrid=expand.grid(C=1)
                         tuneLength=5,
                         na.action=na.exclude)
#apply model on testing
Model.svmLinear <- predict(Train.svmLinear, testing, type="raw")
Model.svmLinear.roc <- predict(Train.svmLinear, testing, type="prob")
#confMatrix
Conf.svmLinear <- confusionMatrix(Model.svmLinear, testing$disease)
```

```{r print_Conf.svmLinear, echo=FALSE}
Conf.svmLinear$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.svmLinear <- Conf.svmLinear$byClass[c("Sensitivity")]
Spec.svmLinear <- Conf.svmLinear$byClass[c("Specificity")]
Acc.svmLinear <- Conf.svmLinear$overall[["Accuracy"]]
F1.svmLinear <- F_meas(Model.svmLinear, testing$disease)
Prec.svmLinear <- Conf.svmLinear$byClass[c("Precision")]
Prev.svmLinear <- Conf.svmLinear$byClass[c("Prevalence")]
tibble(
  Method=c("Svm linear"), 
  Sensitivity=c(Sens.svmLinear),
  Specificity=c(Spec.svmLinear),
  Accuracy=c(Acc.svmLinear)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

\newpage

## K-nearest neighbors  
Another modeling apporach in this project is the k-nearest neighbors model. Using a tuneLength of 3 the train function searches for the optimal size of neighbors to be based on as a tuning parameter.  
```{r Train.knn}
Train.knn <- caret::train(disease.no.disease~., data=training.onehot,
                   method="knn",
                   trControl=control.repeat,
                   # tuneGrid=expand.grid(k=5)
                   tuneLength=3,
                   na.action=na.exclude)
#apply model on testing
Model.knn <- predict(Train.knn, testing.onehot, type="raw")
Model.knn.roc <- predict(Train.knn, testing.onehot, type="prob")
#confMatrix
Conf.knn <- confusionMatrix(Model.knn, testing.onehot$disease)
```

```{r print_Conf.knn, echo=FALSE}
Conf.knn$table %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
Sens.knn <- confusionMatrix(Model.knn, testing.onehot$disease)$byClass[c("Sensitivity")]
Spec.knn <- confusionMatrix(Model.knn, testing.onehot$disease)$byClass[c("Specificity")]
Acc.knn <- confusionMatrix(Model.knn, testing.onehot$disease)$overall[["Accuracy"]]
F1.knn <- F_meas(Model.knn, testing.onehot$disease)
Prec.knn <- Conf.knn$byClass[c("Precision")]
Prev.knn <- Conf.knn$byClass[c("Prevalence")]
tibble(
  Method=c("K-nearest neighbors"), 
  Sensitivity=c(Sens.knn),
  Specificity=c(Spec.knn),
  Accuracy=c(Acc.knn)
  ) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

\newpage

# Results/Evaluation metrics  

## confusion matrix (derivations)  

With different models passed through there is now a bunch of metrics by which we can justify what model is the best to use for the heart disease problem. Besides collecting standard measures for evaluating different models for the problem, we have to take a closer look on the problem itself and its sector of use and consequences of using the model in order to treat patients right.  

Usually the focus of prediction approaches in the medical field should be on **reducing false negative results** to prevent overlooking diseases of a patient. Therefore receiving false negative cases is worse than receiving false positive cases. With this approach we will assess the different models.  
**Sensitivity/Recall** also called true positive rate provides information about how precise the model is in order of finding all patients with heart disease. We can see that the **logistic regression** as well as the **random forest** have the highest sensitivities of **90.0% (87.5%)** which means, that around nine out of ten patients that have heart disease were diagnosed correctly. **K-nearest neighbors** estimate shows a poor result for sensitivity of **62.5%**, only diagnosing six out of ten patients correctly. In terms of **specificity**, all methods except of **decision tree** show a good result.  
**Logistic regression, random forest and support vector machine** are the only methods that show an **overall accuracy** **over 80.0%** as well as a **F1-score** **over 80.0%**.  
With a focus on keeping false negative cases as low as possible **logistic regression** and **support vector machine** bring solid metric values **over 85.0%** in every single metric.  
```{r evaluation.metrics, echo=FALSE, message=FALSE}
tibble("Method"=c("Logistic regression",
                "Decision tree", 
                "Random forest", 
                "Support vector machine (linear)",
                "k-nearest neighbors"),
       "Sensitivity/Recall"=c(
         Sens.glm,
         Sens.dec.tree,
         Sens.random.forest,
         Sens.svmLinear,
         Sens.knn
       ),
       "Specificity"=c(
         Spec.glm,
         Spec.dec.tree,
         Spec.random.forest,
         Spec.svmLinear,
         Spec.knn
         ),
       "Accuracy"=c(Acc.glm,
           Acc.dec.tree,
           Acc.random.forest, 
           Acc.svmLinear,
           Acc.knn
           ),
      "F1-score"=c(F1.glm,
          F1.dec.tree,
          F1.random.forest,
          F1.svmLinear,
          F1.knn),
      "Precision"=c(Prec.glm,
                  Prec.dec.tree,
                  Prec.random.forest,
                  Prec.svmLinear,
                  Prec.knn)
) %>%
  knitr::kable() %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

## roc-curve and auc  

The prevalence (disease/total) is at 45.9% for the set of 303 patients. This means that the number of patients with and without disease is well balanced. That is the reason why the following plot of roc-curves will measure **false positive rate** vs. **true positive rate** and not **precision** vs. **true positive rate**.

As of the roc-curve plot below we can see that **support vector machine** and **random forest** have the highest percentage of area under the roc-curve **(auc)** of **>94.0%**. Auc of **logistic regression** is close to these values so the best decision is to choose one of the three models for the heart disease problem.

```{r roc.glm, echo=FALSE, message=FALSE, comment=NA}
#ROC-curve (roc.curve)
par(pty="s")
pROC::roc(response=testing$disease,
          predictor=Model.glm.roc$disease,
          plot=TRUE,
          print.auc=TRUE,
          print.auc.x=30,
          print.auc.y=68,
          # partial.auc=c(100, 80),
          legacy.axes=TRUE,
          percent=TRUE,
          xlab="False Positive Rate",
          ylab="True Positive Rate",
          col="#32a89e",
          lwd=3)
pROC::plot.roc(testing$disease,
               Model.dec.tree.roc$disease,
               print.auc=TRUE,
               print.auc.x=30,
               print.auc.y=62,
               percent=TRUE,
               add=TRUE,
               col="#3267a8",
               lwd=3)
pROC::plot.roc(testing$disease,
               Model.random.forest.roc$disease,
               print.auc=TRUE,
               print.auc.x=30,
               print.auc.y=56,
               percent=TRUE,
               add=TRUE,
               col="#3d2cab",
               lwd=3)
pROC::plot.roc(testing$disease,
               Model.svmLinear.roc$disease,
               print.auc=TRUE,
               print.auc.x=30,
               print.auc.y=50,
               percent=TRUE,
               add=TRUE,
               col="#a625b8",
               lwd=3)
pROC::plot.roc(testing.onehot$disease.no.disease,
               Model.knn.roc$disease,
               print.auc=TRUE,
               print.auc.x=30,
               print.auc.y=44,
               percent=TRUE,
               add=TRUE,
               col="#c91e5a",
               lwd=3)
legend("bottomright",
       legend=c("log. regression", 
                "decision tree", 
                "random forest", 
                "svm"
                ,"knn"),
       col=c("#32a89e", 
             "#3267a8", 
             "#3d2cab", 
             "#a625b8"
             ,"#c91e5a"),
       lwd=3)
par(pty="m")
```

# Conclusion  

Since some methods like random forest and logistic regression show sufficient results, the attributes of the dataset seem to be good indicators to predict heart disease. However the dataset was released in 1988 around 33 years ago. It can be assumed that there are additional attributes to diagnose patients to have heart disease but more precisely.  